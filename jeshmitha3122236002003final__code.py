# -*- coding: utf-8 -*-
"""Jeshmitha3122236002003Final _code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mzE39ljNC7AMKtE0gKVh9KniowEaAP0X

CASELAWBERT
"""

pip install transformers datasets seqeval torch accelerate

pip install dataset

pip install evaluate

from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForTokenClassification

# Load the dataset
dataset = load_dataset("AjayMukundS/Indian_Legal_NER_Dataset")

# Load the tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("law-ai/InCaseLawBERT")
model = AutoModelForTokenClassification.from_pretrained("law-ai/InCaseLawBERT", num_labels=12)  # 12 legal entity types

# Modify label mapping to include BIO tags
bio_labels = set()
for label in labels:
    bio_labels.add(f"B-{label}")  # Beginning of entity
    bio_labels.add(f"I-{label}")  # Inside entity
bio_labels.add("O")  # Outside entity

# Create BIO-aware mapping
label2id = {label: i for i, label in enumerate(sorted(bio_labels))}
id2label = {i: label for label, i in label2id.items()}

print("Updated Label Mapping:", label2id)  # Debug: Print updated mappings

from evaluate import load
import numpy as np

# Load seqeval for Named Entity Recognition (NER) evaluation
metric = load("seqeval")

def compute_metrics(p):
    predictions, labels = p
    predictions = np.argmax(predictions, axis=2)

    true_predictions = [[id2label[p] for p in pred] for pred in predictions]
    true_labels = [[id2label[l] for l in label] for label in labels]

    return metric.compute(predictions=true_predictions, references=true_labels)

model.save_pretrained("./incaselawbert-legal-ner")
tokenizer.save_pretrained("./incaselawbert-legal-ner")

def predict_entities(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="max_length", max_length=512)
    outputs = model(**inputs)
    predictions = outputs.logits.argmax(-1).squeeze().tolist()

    tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"].squeeze())
    entities = [(token, id2label[pred]) for token, pred in zip(tokens, predictions) if pred != label2id["O"]]

    return entities

# Test the trained model
text = "Justice Sharma presided over the Supreme Court hearing involving RajeshKumar."
print(predict_entities(text))

def predict_entities(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="max_length", max_length=512)
    outputs = model(**inputs)
    predictions = outputs.logits.argmax(-1).squeeze().tolist()

    tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"].squeeze())
    entities = [(token, id2label[pred]) for token, pred in zip(tokens, predictions) if pred != label2id["O"]]

    return entities

from datasets import load_dataset
from transformers import (
    AutoTokenizer, AutoModelForTokenClassification,
    TrainingArguments, Trainer, DataCollatorForTokenClassification
)
from seqeval.metrics import classification_report
import numpy as np
import torch
from pprint import pprint
import json
import pandas as pd

# Load dataset
dataset = load_dataset("AjayMukundS/Indian_Legal_NER_Dataset")
dataset["train"] = dataset["train"].select(range(500))
dataset["validation"] = dataset["validation"].select(range(100))

# Load tokenizer and model
model_name = "zlucia/legalbert"
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.add_prefix_space = True

# Filter out examples with more than 512 tokens
def filter_examples(example):
    tokenized = tokenizer(example["text"], truncation=False)
    return len(tokenized["input_ids"]) <= 512

dataset["train"] = dataset["train"].filter(filter_examples)
dataset["validation"] = dataset["validation"].filter(filter_examples)

# Create label mappings
unique_labels = set()
for split in ["train", "validation"]:
    for example in dataset[split]["entities"]:
        for entity in example:
            unique_labels.add("B-" + entity["label"])
            unique_labels.add("I-" + entity["label"])

label_list = sorted(list(unique_labels))
label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

# Tokenization and label alignment
def tokenize_and_align_labels(example):
    words = example["text"].split()
    tokenized = tokenizer(words, is_split_into_words=True)
    labels = [-100] * len(tokenized["input_ids"])
    word_ids = tokenized.word_ids()

    for entity in example["entities"]:
        ent_start, ent_end, ent_label = entity["start"], entity["end"], entity["label"]
        if f"B-{ent_label}" not in label2id or f"I-{ent_label}" not in label2id:
            continue
        B_id = label2id[f"B-{ent_label}"]
        I_id = label2id[f"I-{ent_label}"]

        for idx, word_idx in enumerate(word_ids):
            if word_idx is not None:
                token_start_end = tokenized.token_to_chars(idx)
                if token_start_end:
                    token_start, token_end = token_start_end.start, token_start_end.end
                    if ent_start <= token_start < token_end <= ent_end:
                        labels[idx] = B_id if token_start == ent_start else I_id

    tokenized["labels"] = labels
    return tokenized

tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=False)
data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)

# Load model
model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))

# Evaluation metric
def compute_metrics(p):
    predictions = np.argmax(p.predictions, axis=2)
    labels = p.label_ids

    true = [[id2label[label] for label in label_seq if label != -100] for label_seq in labels]
    pred = [[id2label[pred] for pred, label in zip(pred_seq, label_seq) if label != -100] for pred_seq, label_seq in zip(predictions, labels)]

    report = classification_report(true, pred, output_dict=True)
    return report

# Training arguments
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=50,
    report_to="none"
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

# Train
trainer.train()

# Evaluate
eval_results = trainer.evaluate()
pprint(eval_results)

# Save metrics
with open("legal_ner_eval_metrics.json", "w") as f:
    json.dump(eval_results, f, indent=4)

pd.DataFrame(eval_results).to_csv("legal_ner_eval_metrics.csv")

# Print key F1 scores
macro_f1 = eval_results.get("macro avg", {}).get("f1-score", "N/A")
overall_f1 = eval_results.get("overall", {}).get("f1-score", "N/A")
print("\n\U0001F4CA F1 Scores:")
print(f"Macro F1 Score: {macro_f1}")
print(f"Overall F1 Score: {overall_f1}")

# Entity prediction function
def predict_entities(text):
    words = text.split()
    inputs = tokenizer(words, return_tensors="pt", is_split_into_words=True)
    with torch.no_grad():
        outputs = model(**inputs)
    predictions = torch.argmax(outputs.logits, dim=2)[0].tolist()
    word_ids = inputs.word_ids()

    entities = []
    for idx, word_idx in enumerate(word_ids):
        if word_idx is not None:
            label_id = predictions[idx]
            label = id2label.get(label_id, "O")
            if label != "O":
                entities.append((words[word_idx], label))
    return entities

# Test
print(predict_entities("The Supreme Court dismissed the petition filed by Advocate Ram Kumar."))

# ✅ Install required packages (run in Colab or Jupyter)
!pip install datasets transformers seqeval scikit-learn

# ✅ Imports
from datasets import load_dataset
from transformers import (
    AutoTokenizer, AutoModelForTokenClassification,
    TrainingArguments, Trainer, DataCollatorForTokenClassification
)
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import numpy as np
import torch

# ✅ Load dataset (first 500 train, 100 validation)
dataset = load_dataset("AjayMukundS/Indian_Legal_NER_Dataset")
dataset["train"] = dataset["train"].select(range(500))
dataset["validation"] = dataset["validation"].select(range(100))

# ✅ Model and Tokenizer
model_name = "zlucia/legalbert"
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.add_prefix_space = True

# ✅ Filter examples > 512 tokens
def filter_examples(example):
    tokenized = tokenizer(example["text"], truncation=False)
    return len(tokenized["input_ids"]) <= 512

dataset["train"] = dataset["train"].filter(filter_examples)
dataset["validation"] = dataset["validation"].filter(filter_examples)

# ✅ Label mapping
unique_labels = set()
for split in ["train", "validation"]:
    for example in dataset[split]["entities"]:
        for entity in example:
            unique_labels.add("B-" + entity["label"])
            unique_labels.add("I-" + entity["label"])
unique_labels.add("O")

label_list = sorted(list(unique_labels))
label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

# ✅ Tokenize and align labels
def tokenize_and_align_labels(example):
    tokenized = tokenizer(example["text"], truncation=True, max_length=512, return_offsets_mapping=True)
    labels = [label2id["O"]] * len(tokenized["input_ids"])

    for entity in example["entities"]:
        ent_start, ent_end, ent_label = entity["start"], entity["end"], entity["label"]
        for idx, (start, end) in enumerate(tokenized["offset_mapping"]):
            if start >= ent_end:
                break
            if start >= ent_start and end <= ent_end:
                if start == ent_start:
                    labels[idx] = label2id[f"B-{ent_label}"]
                else:
                    labels[idx] = label2id[f"I-{ent_label}"]

    tokenized["labels"] = labels
    tokenized.pop("offset_mapping")
    return tokenized

tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=False)
data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)

# ✅ Load model
model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))

# ✅ Training setup
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=10,
    report_to="none"
)

# ✅ Define Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator
)

# ✅ Train model
trainer.train()

# ✅ Predict on validation set
outputs = trainer.predict(tokenized_datasets["validation"])
predictions = np.argmax(outputs.predictions, axis=2)
labels = outputs.label_ids

true_labels = []
pred_labels = []

for pred_seq, label_seq in zip(predictions, labels):
    for pred, label in zip(pred_seq, label_seq):
        if label != -100:
            true_labels.append(label)
            pred_labels.append(pred)

# ✅ Compute overall metrics
overall_accuracy = accuracy_score(true_labels, pred_labels)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average="weighted")

print("\n📈 Overall Evaluation Metrics (CaseLawBERT):")
print(f"Accuracy:  {overall_accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1 Score:  {f1:.4f}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Example true and predicted labels
true_labels = ['B-COURT', 'B-COURT', 'B-OTHER_PERSON', 'B-COURT']  # From dataset
pred_labels_roberta = ['B-COURT', 'B-OTHER_PERSON', 'B-OTHER_PERSON', 'B-COURT']  # From RoBERTaBERT
pred_labels_caselaw = ['B-COURT', 'B-COURT', 'B-COURT', 'B-COURT']  # From CaseLawBERT

# Get unique labels (union of all)
unique_labels = sorted(set(true_labels + pred_labels_roberta + pred_labels_caselaw))

# Create label-to-index mapping
label_to_index = {label: idx for idx, label in enumerate(unique_labels)}

# Convert string labels to index
true_indices = [label_to_index[label] for label in true_labels]
roberta_indices = [label_to_index[label] for label in pred_labels_roberta]
caselaw_indices = [label_to_index[label] for label in pred_labels_caselaw]

# Compute confusion matrices
cm_roberta = confusion_matrix(true_indices, roberta_indices)
cm_caselaw = confusion_matrix(true_indices, caselaw_indices)

# Plot RoBERTaBERT
plt.figure(figsize=(10, 4))
sns.heatmap(cm_roberta, annot=True, fmt='d', xticklabels=unique_labels, yticklabels=unique_labels, cmap='Blues')
plt.title("Confusion Matrix - RoBERTaBERT")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Plot CaseLawBERT
plt.figure(figsize=(10, 4))
sns.heatmap(cm_caselaw, annot=True, fmt='d', xticklabels=unique_labels, yticklabels=unique_labels, cmap='Greens')
plt.title("Confusion Matrix - CaseLawBERT")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Define data
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
roberta_values = [0.7514, 0.8408, 0.7514, 0.7922]
caselaw_values = [0.5544, 0.7777, 0.5544, 0.6437]

# Create a DataFrame
data = pd.DataFrame({
    'RoBERTaBERT': roberta_values,
    'CaseLawBERT': caselaw_values
}, index=metrics)

# Plot heatmap
plt.figure(figsize=(8, 4))
sns.heatmap(data, annot=True, cmap='YlGnBu', fmt=".4f", cbar=True)
plt.title("Model Evaluation Metrics Heatmap")
plt.ylabel("Metrics")
plt.tight_layout()
plt.show()

"""ROBERTaBERT"""

# Install necessary packages
!pip install datasets transformers seqeval scikit-learn pandas

# Import packages
from datasets import load_dataset
from transformers import (
    AutoTokenizer, AutoModelForTokenClassification,
    TrainingArguments, Trainer, DataCollatorForTokenClassification
)
from seqeval.metrics import classification_report
from sklearn.metrics import confusion_matrix
import numpy as np
import torch
from pprint import pprint
import json
import pandas as pd

# Load dataset
dataset = load_dataset("AjayMukundS/Indian_Legal_NER_Dataset")
dataset["train"] = dataset["train"].select(range(500))
dataset["validation"] = dataset["validation"].select(range(100))

# Load tokenizer and model
model_name = "roberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.add_prefix_space = True

# Filter out long examples
def filter_examples(example):
    tokenized = tokenizer(example["text"], truncation=False)
    return len(tokenized["input_ids"]) <= 512

dataset["train"] = dataset["train"].filter(filter_examples)
dataset["validation"] = dataset["validation"].filter(filter_examples)

# Create label mappings
unique_labels = set()
for split in ["train", "validation"]:
    for example in dataset[split]["entities"]:
        for entity in example:
            unique_labels.add("B-" + entity["label"])
            unique_labels.add("I-" + entity["label"])
unique_labels.add("O")

label_list = sorted(list(unique_labels))
label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

# Tokenize and align labels
def tokenize_and_align_labels(example):
    tokenized = tokenizer(example["text"], truncation=True, max_length=512, return_offsets_mapping=True)
    labels = [label2id["O"]] * len(tokenized["input_ids"])

    for entity in example["entities"]:
        ent_start, ent_end, ent_label = entity["start"], entity["end"], entity["label"]
        for idx, (start, end) in enumerate(tokenized["offset_mapping"]):
            if start >= ent_end:
                break
            if start >= ent_start and end <= ent_end:
                if start == ent_start:
                    labels[idx] = label2id[f"B-{ent_label}"]
                else:
                    labels[idx] = label2id[f"I-{ent_label}"]

    tokenized["labels"] = labels
    tokenized.pop("offset_mapping")
    return tokenized

tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=False)
data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)

# Load model
model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))

# Evaluation and confusion matrix
def compute_metrics(p):
    predictions = np.argmax(p.predictions, axis=2)
    labels = p.label_ids

    true = [[id2label[label] for label in label_seq if label != -100] for label_seq in labels]
    pred = [[id2label[pred] for pred, label in zip(pred_seq, label_seq) if label != -100] for pred_seq, label_seq in zip(predictions, labels)]

    flat_true = [item for sublist in true for item in sublist]
    flat_pred = [item for sublist in pred for item in sublist]
    cm = confusion_matrix(flat_true, flat_pred, labels=label_list)

    report = classification_report(true, pred, output_dict=True, zero_division=0)
    macro_f1 = report.get("macro avg", {}).get("f1-score", 0)
    micro_f1 = report.get("micro avg", {}).get("f1-score", 0)

    return {
        "classification_report": report,
        "confusion_matrix": cm,
        "macro_f1": macro_f1,
        "micro_f1": micro_f1
    }

# Training setup
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=10,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

# Train and evaluate
trainer.train()
eval_results = trainer.evaluate()

# Save and display results
report = eval_results.get("classification_report", {})
conf_matrix = eval_results.get("confusion_matrix", None)

with open("robertabert_legal_ner_eval_metrics.json", "w") as f:
    json.dump(report, f, indent=4)

pd.DataFrame(report).transpose().to_csv("robertabert_legal_ner_classification_report.csv")

if conf_matrix is not None:
    print("\n📊 Confusion Matrix:")
    conf_df = pd.DataFrame(conf_matrix, index=label_list, columns=label_list)
    print(conf_df)
    conf_df.to_csv("robertabert_legal_ner_confusion_matrix.csv")

# F1 Scores
macro_f1 = eval_results.get("macro_f1", "N/A")
micro_f1 = eval_results.get("micro_f1", "N/A")
print("\n📈 F1 Scores:")
print(f"Macro F1 Score: {macro_f1}")
print(f"Micro F1 Score: {micro_f1}")

# Prediction example
def predict_entities(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True)
    inputs = {k: v.to(model.device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
    predictions = torch.argmax(outputs.logits, dim=2)[0].tolist()
    tokens = tokenizer.convert_ids_to_tokens(inputs["input_ids"][0])

    entities = []
    for token, label_id in zip(tokens, predictions):
        label = id2label[label_id]
        if label != "O":
            entities.append((token, label))
    return entities

# Example test
print("\n🔍 Predicted Entities:")
print(predict_entities("The Supreme Court dismissed the petition filed by Advocate Ram Kumar."))

from sklearn.metrics import confusion_matrix
import pandas as pd

# Extract predictions and labels
predictions, labels, _ = trainer.predict(tokenized_datasets["validation"])
pred_labels = np.argmax(predictions, axis=2)

# Convert label IDs to strings
true_labels = []
predicted_labels = []

for true_seq, pred_seq in zip(labels, pred_labels):
    for true_id, pred_id in zip(true_seq, pred_seq):
        if true_id != -100:
            true_labels.append(id2label[true_id])
            predicted_labels.append(id2label[pred_id])

# Compute confusion matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=label_list)

# Convert to DataFrame for readability
conf_df = pd.DataFrame(conf_matrix, index=label_list, columns=label_list)

# Print and save confusion matrix
print("\n📊 Confusion Matrix:")
print(conf_df)
conf_df.to_csv("robertabert_legal_ner_confusion_matrix.csv")

# Install required packages (if running in a new environment like Colab)
!pip install datasets transformers seqeval scikit-learn --quiet

# Imports
from datasets import load_dataset
from transformers import AutoTokenizer
import pandas as pd

# Step 1: Load the dataset
dataset = load_dataset("AjayMukundS/Indian_Legal_NER_Dataset")

# Step 2: Take first 100 records from train split
subset = dataset["train"].select(range(100))

# Step 3: Load tokenizer
tokenizer = AutoTokenizer.from_pretrained("roberta-base")
tokenizer.add_prefix_space = True

# Step 4: Create label mappings
unique_labels = set()
for example in subset["entities"]:
    for ent in example:
        unique_labels.add(f"B-{ent['label']}")
        unique_labels.add(f"I-{ent['label']}")
unique_labels.add("O")

label_list = sorted(list(unique_labels))
label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

# Step 5: Tokenize and align labels
def tokenize_and_align_labels(example):
    tokenized = tokenizer(example["text"], return_offsets_mapping=True, truncation=True, max_length=512)
    labels = [label2id["O"]] * len(tokenized["input_ids"])

    for ent in example["entities"]:
        ent_start, ent_end, ent_label = ent["start"], ent["end"], ent["label"]
        for idx, (start, end) in enumerate(tokenized["offset_mapping"]):
            if start >= ent_end:
                break
            if start >= ent_start and end <= ent_end:
                if start == ent_start:
                    labels[idx] = label2id[f"B-{ent_label}"]
                else:
                    labels[idx] = label2id[f"I-{ent_label}"]

    tokenized["labels"] = labels
    tokenized.pop("offset_mapping")
    return tokenized

# Step 6: Apply tokenization
tokenized_subset = subset.map(tokenize_and_align_labels, batched=False)

# ✅ Optional: View one example
print("Example Tokenized Input:")
print(tokenizer.convert_ids_to_tokens(tokenized_subset[0]["input_ids"]))
print("Labels:")
print([id2label[id] for id in tokenized_subset[0]["labels"]])

# Install necessary libraries
!pip install datasets transformers seqeval scikit-learn --quiet

# Imports
from datasets import load_dataset
from transformers import (
    AutoTokenizer, AutoModelForTokenClassification,
    TrainingArguments, Trainer, DataCollatorForTokenClassification
)
from seqeval.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import torch
import pandas as pd
import matplotlib.pyplot as plt

# Load dataset (first 500 records only)
dataset = load_dataset("AjayMukundS/Indian_Legal_NER_Dataset")
dataset["train"] = dataset["train"].select(range(500))
dataset["validation"] = dataset["validation"].select(range(100))

# Load tokenizer and model
model_name = "roberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.add_prefix_space = True

# Filter long examples (>512 tokens)
def filter_examples(example):
    tokenized = tokenizer(example["text"], truncation=False)
    return len(tokenized["input_ids"]) <= 512

dataset["train"] = dataset["train"].filter(filter_examples)
dataset["validation"] = dataset["validation"].filter(filter_examples)

# Create label mappings
unique_labels = set()
for split in ["train", "validation"]:
    for example in dataset[split]["entities"]:
        for entity in example:
            unique_labels.add("B-" + entity["label"])
            unique_labels.add("I-" + entity["label"])
unique_labels.add("O")  # Outside tag

label_list = sorted(list(unique_labels))
label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

# Tokenize and align labels
def tokenize_and_align_labels(example):
    tokenized = tokenizer(example["text"], truncation=True, max_length=512, return_offsets_mapping=True)
    labels = [label2id["O"]] * len(tokenized["input_ids"])

    for entity in example["entities"]:
        ent_start, ent_end, ent_label = entity["start"], entity["end"], entity["label"]
        for idx, (start, end) in enumerate(tokenized["offset_mapping"]):
            if start >= ent_end:
                break
            if start >= ent_start and end <= ent_end:
                if start == ent_start:
                    labels[idx] = label2id[f"B-{ent_label}"]
                else:
                    labels[idx] = label2id[f"I-{ent_label}"]

    tokenized["labels"] = labels
    tokenized.pop("offset_mapping")
    return tokenized

tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=False)
data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)

# Load model
model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))

# Compute metrics
def compute_metrics(p):
    predictions = np.argmax(p.predictions, axis=2)
    labels = p.label_ids

    true = [[id2label[label] for label in label_seq if label != -100] for label_seq in labels]
    pred = [[id2label[pred] for pred, label in zip(pred_seq, label_seq) if label != -100] for pred_seq, label_seq in zip(predictions, labels)]

    report = classification_report(true, pred, output_dict=True, zero_division=0)
    return report

# Training arguments
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=10,
    report_to="none"
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

# Evaluate the model
eval_results = trainer.evaluate()
print("\n📊 Evaluation Results:")
for k, v in eval_results.items():
    print(f"{k}: {v}")

# Generate confusion matrix for flat labels
true_labels = []
pred_labels = []

outputs = trainer.predict(tokenized_datasets["validation"])
predictions = np.argmax(outputs.predictions, axis=2)
labels = outputs.label_ids

for pred_seq, label_seq in zip(predictions, labels):
    for pred, label in zip(pred_seq, label_seq):
        if label != -100:
            true_labels.append(id2label[label])
            pred_labels.append(id2label[pred])

# Filter common labels
labels_to_display = sorted(list(set(true_labels + pred_labels)))
cm = confusion_matrix(true_labels, pred_labels, labels=labels_to_display)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_to_display)
fig, ax = plt.subplots(figsize=(12, 12))
disp.plot(ax=ax, xticks_rotation=90, cmap="Blues")
plt.title("Confusion Matrix - Legal NER with RoBERTa")
plt.show()

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# Step 1: Extract predicted and true labels (already done during confusion matrix computation)
true_labels = []
pred_labels = []

outputs = trainer.predict(tokenized_datasets["validation"])
predictions = np.argmax(outputs.predictions, axis=2)
labels = outputs.label_ids

for pred_seq, label_seq in zip(predictions, labels):
    for pred, label in zip(pred_seq, label_seq):
        if label != -100:
            true_labels.append(label)
            pred_labels.append(pred)

# Step 2: Compute overall metrics
overall_accuracy = accuracy_score(true_labels, pred_labels)
precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average="weighted")

# Step 3: Print
print("\n📈 Overall Evaluation Metrics:")
print(f"Accuracy:  {overall_accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1 Score:  {f1:.4f}")